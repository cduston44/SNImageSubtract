{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59934be",
   "metadata": {},
   "source": [
    "This sheet is TESTING for one science image and one ref image.\n",
    "\n",
    "Ok so this here sheet is going to be the full image subtraction routine for SN photometry. Note that it is being written to be applied to a single filter at a time, for simplicity!\n",
    "\n",
    "Note that following the original script from GROWTH 2020, this script will remove the processed directories when you run it, so careful!\n",
    "\n",
    "Also note that we assume the images have already been rotated (via that script), and have a valid WCS. I've included the WCS routine in the rotation sheet, so we should be good there.\n",
    "\n",
    "The source directory should contain just the rotated source images. The data directory will be created by this code as the sources images + conifguration files, and the processed directory will be....the processed directory! This is awkward, but can't really figure out how to make it work otherwise...\n",
    "\n",
    "\n",
    "Actually, this version is intended for use on a cropped image, but that's done in the rotation script, so no major changes here (except to determine the size of the images dynamically).\n",
    "\n",
    "First import relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbfc541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os  #Call commands from outside Python\n",
    "import numpy as np\n",
    "\n",
    "# Running external programs\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "from astropy.coordinates import SkyCoord # For the catalog analysis during normalization\n",
    "\n",
    "from astropy.io import fits #FITS files handling\n",
    "from astropy.io import ascii  #Read/write ascii files\n",
    "\n",
    "# Background subtraction\n",
    "import photutils\n",
    "#from photutils.detection import DAOStarFinder\n",
    "from photutils.segmentation import detect_threshold, detect_sources\n",
    "#from photutils import Background2D, MedianBackground # old version\n",
    "from photutils.background import Background2D, MedianBackground \n",
    "from astropy.stats import sigma_clipped_stats, SigmaClip # statistics\n",
    "from photutils.utils import circular_footprint\n",
    "\n",
    "# Image registration and shifting\n",
    "from image_registration import chi2_shift\n",
    "from image_registration.fft_tools import shift\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "# Useful to smooth the images with a Gaussian kernel before the subtraction\n",
    "from scipy.signal import convolve as scipy_convolve\n",
    "\n",
    "# For rotation\n",
    "import astroalign as aa\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Math help\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a83eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You start from the directory: /home/cduston/GoogleDrive/Research/MCARG/Novae/SN2023ctn/image_subtraction\n",
      "You are working in the image_subtraction/processed/ directory: \n",
      "Full path: /home/cduston/GoogleDrive/Research/MCARG/Novae/SN2023ctn/image_subtraction/processed\n"
     ]
    }
   ],
   "source": [
    "# Set directory structure\n",
    "cwd = os.getcwd()\n",
    "\n",
    "print(\"You start from the directory:\", cwd)\n",
    "\n",
    "source_dir = os.path.join(cwd, 'source') # All the stacked, rotated files should be in here\n",
    "data_dir = os.path.join(cwd, 'data') # empty, but will get rewritten.\n",
    "if os.path.isdir(data_dir): # checks and removes if it exists. \n",
    "    shutil.rmtree(data_dir)\n",
    "os.mkdir(data_dir)\n",
    "proc_dir = os.path.join(cwd, 'processed') # all processes fits files.\n",
    "out_dir = os.path.join(proc_dir, 'out') # output files are here\n",
    "if os.path.isdir(proc_dir): # checks and removes if it exists. \n",
    "    shutil.rmtree(proc_dir)\n",
    "os.mkdir(proc_dir)\n",
    "config_dir = os.path.join(cwd, 'config') # various configuration files, should exist!\n",
    "if os.path.exists(config_dir)==False:\n",
    "    print(\"Error, config directory does not exist!\")\n",
    "    raise\n",
    "\n",
    "for f in os.listdir(source_dir): # copy sources into data directory.\n",
    "    shutil.copy2(os.path.join(source_dir, f), os.path.join(data_dir,f))\n",
    "for f in os.listdir(config_dir): # copy configuration into data directory.\n",
    "    shutil.copy2(os.path.join(config_dir, f), data_dir)\n",
    "for f in os.listdir(data_dir): # copy data into processed and change to it.\n",
    "    shutil.copy2(os.path.join(data_dir, f), proc_dir)\n",
    "\n",
    "os.chdir(proc_dir)\n",
    "print(\"You are working in the image_subtraction/processed/ directory: \")\n",
    "print(\"Full path:\", proc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa14244",
   "metadata": {},
   "source": [
    "Need to get the list of rotated images (since that used to be part of this script!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ee6ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUM_Aligned_20230308_I_Rotated.fits',\n",
       " 'SUM_Aligned_20230309_B_Rotated.fits',\n",
       " 'SUM_Aligned_20230309_I_Rotated.fits',\n",
       " 'SUM_Aligned_20230310_B_Rotated.fits',\n",
       " 'SUM_Aligned_20230310_I_Rotated.fits',\n",
       " 'SUM_Aligned_20230311_B_Rotated.fits',\n",
       " 'SUM_Aligned_20230311_I_Rotated.fits',\n",
       " 'SUM_Aligned_20230312_B_Rotated.fits',\n",
       " 'SUM_Aligned_20230312_I_Rotated.fits',\n",
       " 'SUM_Aligned_20230313_B_Rotated.fits',\n",
       " 'SUM_Aligned_20230313_I_Rotated.fits',\n",
       " 'SUM_Aligned_20240116_I_Rotated.fits',\n",
       " 'SUM_Aligned_20240116_R_Rotated.fits',\n",
       " 'SUM_Aligned_20240119_B_Rotated.fits',\n",
       " 'SUM_Aligned_20240119_I_Rotated.fits']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_name_array=[]\n",
    "for f in os.listdir(source_dir): # create list of raw images\n",
    "    rot_name_array.append(f)\n",
    "    \n",
    "rot_name_array.sort() # sorted by name so that discovery is first.\n",
    "rot_name_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624bab47",
   "metadata": {},
   "source": [
    "## Subtraction Routine\n",
    "\n",
    "This part comes from the GROWTH 2020 school, with my own modifications and dealing with some recent changes to the code. We'll start with a dependency check:\n",
    "\n",
    "(for now skipping all reference to ds9, since that doesn't actually seem that useful atm.)\n",
    "\n",
    "the rest of this is for FAILED Slackware installation!\n",
    "\n",
    "installing these things was kind of a nightmare...these instructions are for Slackware...\n",
    "\n",
    "Swarp: https://www.astromatic.net/software download source. run autogen? ./configure, make, su, make install...\n",
    "\n",
    "SExtractor https://www.astromatic.net/software source....will need ATLAS and FFTW. trying autogen. ATLAS not in 15.0 yet! Guess I'll switch to System76 and try old Slackbuilds. Ugh ATLAS does not seem to build on Slack 15.0 (email thread). Trying the intel MKL approach...following wget instructions from https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html?operatingsystem=linux&distributions=offline. Compatibility warnings, proceeding...isntall location /opt/intel/oneapi. Failing lots of prereqs. All gui, so just pushing forward. Skip eclipse. Need g++, but I actually have that installed, it just can't find it. continuing...says done. trying to configure with --enable-mkl, but cannot find c compilter. \n",
    "\n",
    "ATLAS alone does not seem to build either on Slackware.....bust!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef0795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sextractor is installed properly as source-extractor. OK\n",
      "SWarp is installed properly as swarp. OK\n",
      "psfex is installed properly as psfex. OK\n",
      "3 out of 3 external dependencies installed properly.\n",
      "\n",
      "You are ready to continue.\n"
     ]
    }
   ],
   "source": [
    "def test_dependency(dep, alternate_name=None):\n",
    "    \"\"\"\n",
    "    Test external dependency by trying to run it as a subprocess\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subprocess.check_output(dep, stderr=subprocess.PIPE, shell=True)\n",
    "        print(\"%s is installed properly as %s. OK\" % (dep, dep))\n",
    "        return 1\n",
    "    except subprocess.CalledProcessError:\n",
    "        try:\n",
    "            subprocess.check_output(alternate_name, stderr=subprocess.PIPE, shell=True)\n",
    "            print(\"%s is installed properly as %s. OK\" % (dep, alternate_name))\n",
    "            return 1\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"===%s/%s IS NOT YET INSTALLED PROPERLY===\" % (dep, alternate_name))\n",
    "            return 0\n",
    "\n",
    "#dependencies = [('sextractor', 'sex'), ('SWarp', 'swarp'), ('psfex', 'PSFEx'), ('ds9', 'DS9')]\n",
    "#dependencies = [('sextractor', 'source-extractor'), ('SWarp', 'swarp'), ('psfex', 'PSFEx'), ('ds9', 'DS9')]\n",
    "dependencies = [('sextractor', 'source-extractor'), ('SWarp', 'swarp'), ('psfex', 'PSFEx')]\n",
    "i = 0\n",
    "for dep_name1, dep_name2 in dependencies:\n",
    "    i += test_dependency(dep_name1, dep_name2)\n",
    "print(\"%i out of %i external dependencies installed properly.\\n\" % (i, len(dependencies)))\n",
    "if i != len(dependencies):\n",
    "    print(\"Please correctly install these programs before continuing by following the instructions in README.md.\")\n",
    "else:\n",
    "    print(\"You are ready to continue.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da90bc",
   "metadata": {},
   "source": [
    "## Align the images\n",
    "\n",
    "Use the AstrOmatic Swarp package to align the images.  Swarp relies on the astrometric information of the image (in other words, on the sky coordinates), therefore both the science and reference images must be astrometrically calibrated (for example, using the AstrOmatic SCAMP package).  In this module we assume that the input images are already calibrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903f25f",
   "metadata": {},
   "source": [
    "We should be trying to pass the entire list to swarp at once, methinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d70388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# rot_image_array=[]\\nswarp_filelist_name=config_dir+\"/\"+\\'swarp_filelist.txt\\'\\nswarp_filelist = open(swarp_filelist_name, \\'w\\')\\nfor f in rot_name_array: \\n    #rot_image_array.append(f)\\n    print(f)\\n    swarp_filelist.write(str(f) + \"\\n\")\\nswarp_filelist.close()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# rot_image_array=[]\n",
    "swarp_filelist_name=config_dir+\"/\"+'swarp_filelist.txt'\n",
    "swarp_filelist = open(swarp_filelist_name, 'w')\n",
    "for f in rot_name_array: \n",
    "    #rot_image_array.append(f)\n",
    "    print(f)\n",
    "    swarp_filelist.write(str(f) + \"\\n\")\n",
    "swarp_filelist.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3e69ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUM_Aligned_20230308_I_Rotated.fits\n",
      "SUM_Aligned_20240119_I_Rotated.fits\n"
     ]
    }
   ],
   "source": [
    "# grab a single science image and reference\n",
    "sci_image_name=rot_name_array[0]\n",
    "print(sci_image_name)\n",
    "#ref_image_name=rot_name_array[1] # As a test, doing two science images!\n",
    "ref_image_name=rot_name_array[len(rot_name_array)-1]\n",
    "print(ref_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd8df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bafc96cf",
   "metadata": {},
   "source": [
    "Note in this next command the size of the box is basically dummy for right now, but it does crop the images (unessicarily, I think). Should just be square at least..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0638fe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Swarp command\\n# had to change capitalization of SWarp!\\ntry:\\n    #command = \"swarp %s %s -c %s -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N -IMAGE_SIZE 1800,900\" % (sci_image_name, ref_image_name, os.path.join(config_dir, \\'config.swarp\\'))\\n    command = \"swarp @%s -c %s -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N -IMAGE_SIZE 1800,900\" % (swarp_filelist_name, os.path.join(config_dir, \\'config.swarp\\'))\\n    print(\\'Executing command: %s\\' % command)\\n    rval = subprocess.run(command.split(), check=True)\\n    print(\\'Success!\\')\\nexcept subprocess.CalledProcessError as err:\\n    print(\\'Could not run SWarp with exit error %s\\'%err)\\n\\n# Gotta fix the names of the aligned images\\nswarp_filelist = open(swarp_filelist_name, \\'r\\')\\nalign_image_array=[]\\nfor line in swarp_filelist:\\n    #print(line)\\n    align_image_array.append(line.strip().replace(\".fits\", \".resamp.fits\").replace(\\'data\\',\\'processed\\'))\\n#sci_image_aligned_name = sci_image_name.replace(\".fits\", \".resamp.fits\").replace(\\'data\\',\\'processed\\')\\n#ref_image_aligned_name = ref_image_name.replace(\".fits\", \".resamp.fits\").replace(\\'data\\',\\'processed\\')\\nswarp_filelist.close()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Swarp command\n",
    "# had to change capitalization of SWarp!\n",
    "try:\n",
    "    #command = \"swarp %s %s -c %s -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N -IMAGE_SIZE 1800,900\" % (sci_image_name, ref_image_name, os.path.join(config_dir, 'config.swarp'))\n",
    "    command = \"swarp @%s -c %s -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N -IMAGE_SIZE 1800,900\" % (swarp_filelist_name, os.path.join(config_dir, 'config.swarp'))\n",
    "    print('Executing command: %s' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SWarp with exit error %s'%err)\n",
    "\n",
    "# Gotta fix the names of the aligned images\n",
    "swarp_filelist = open(swarp_filelist_name, 'r')\n",
    "align_image_array=[]\n",
    "for line in swarp_filelist:\n",
    "    #print(line)\n",
    "    align_image_array.append(line.strip().replace(\".fits\", \".resamp.fits\").replace('data','processed'))\n",
    "#sci_image_aligned_name = sci_image_name.replace(\".fits\", \".resamp.fits\").replace('data','processed')\n",
    "#ref_image_aligned_name = ref_image_name.replace(\".fits\", \".resamp.fits\").replace('data','processed')\n",
    "swarp_filelist.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a21de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sizes: 2240 1790\n",
      "Executing command: swarp SUM_Aligned_20230308_I_Rotated.fits SUM_Aligned_20240119_I_Rotated.fits -c /home/cduston/GoogleDrive/Research/MCARG/Novae/SN2023ctn/image_subtraction/config/config.swarp -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N -IMAGE_SIZE YSIZE,XSIZE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1M> \n",
      "\u001b[1A----- SWarp 2.41.5 started on 2024-04-12 at 15:52:47 with 12 threads\n",
      "\n",
      "\u001b[1M> Examining input data ...\n",
      "\u001b[1A\u001b[1M> Looking for SUM_Aligned_20230308_I_Rotated.fits ...\n",
      "\u001b[1A\u001b[1M> Looking for SUM_Aligned_20240119_I_Rotated.fits ...\n",
      "\u001b[1A\u001b[1M> Creating NEW output image ...\n",
      "\u001b[1A\u001b[1M> Creating NEW weight-map ...\n",
      "\u001b[1A\u001b[1M> \n",
      "\u001b[1A------- Output File swarpout.fits:\n",
      "    \"no ident\"  WEIGHTED  no ext. header  2500x2066  32 bits (floats)\n",
      "    Center: 08:33:00.28 -27:26:58.6   29.9'x24.7'  Scale: 0.7172 ''/pixel\n",
      "    Gain: 0 e-/ADU   Flux scaling (astrom/photom): 1 X / 1 X\n",
      "\n",
      "\u001b[1M> Loading input data ...\n",
      "\u001b[1A\u001b[1M> \n",
      "\u001b[1A-------------- File SUM_Aligned_20230308_I_Rotated.fits:\n",
      "    \"no ident\"  unweighted  no ext. header  2250x1800  32 bits (floats)\n",
      "    Center: 08:33:00.18 -27:26:59.3   26.9'x21.5'  Scale: 0.7172 ''/pixel\n",
      "    Gain: 4 e-/ADU   Flux scaling (astrom/photom): 1 X / 1 X\n",
      "\u001b[1M> Setting up background maps ...\n",
      "\u001b[1A\u001b[1M> Setting up background map at line:    512 / 1800   \n",
      "\u001b[1A\u001b[1M> Setting up background map at line:   1024 / 1800   \n",
      "\u001b[1A\u001b[1M> Setting up background map at line:   1536 / 1800   \n",
      "\u001b[1A\u001b[1M> Filtering background map(s) ...\n",
      "\u001b[1A\u001b[1M> Computing backgound d-map ...\n",
      "\u001b[1A\u001b[1M> Computing backgound-noise d-map ...\n",
      "\u001b[1A    Background: 2883.351   RMS: 71.69\n",
      "\n",
      "\u001b[1M> Reading SUM_Aligned_20230308_I_Rotated.fits\n",
      "\u001b[1A\u001b[1M> Resampling SUM_Aligned_20230308_I_Rotated.fits ...\n",
      "\u001b[1A\u001b[1M> Resampling line:      0 / 1970   \n",
      "\u001b[1A\u001b[1M> Resampling line:    251 / 1970   \n",
      "\u001b[1A\u001b[1M> Resampling line:    502 / 1970   \n",
      "\u001b[1A\u001b[1M> Resampling line:    753 / 1970   \n",
      "\u001b[1A\u001b[1M> Resampling line:   1004 / 1970   \n",
      "\u001b[1A\u001b[1M> Resampling line:   1255 / 1970   \n",
      "\u001b[1A\u001b[1M> Resampling line:   1506 / 1970   \n",
      "\u001b[1A\u001b[1M> Resampling line:   1757 / 1970   \n",
      "\u001b[1A\u001b[1M> \n",
      "\u001b[1A-------------- File SUM_Aligned_20240119_I_Rotated.fits:\n",
      "    \"no ident\"  unweighted  no ext. header  2250x1800  32 bits (floats)\n",
      "    Center: 08:33:00.18 -27:26:59.2   26.9'x21.5'  Scale: 0.7172 ''/pixel\n",
      "    Gain: 4 e-/ADU   Flux scaling (astrom/photom): 1 X / 1 X\n",
      "\u001b[1M> Setting up background maps ...\n",
      "\u001b[1A\u001b[1M> Setting up background map at line:    512 / 1800   \n",
      "\u001b[1A\u001b[1M> Setting up background map at line:   1024 / 1800   \n",
      "\u001b[1A\u001b[1M> Setting up background map at line:   1536 / 1800   \n",
      "\u001b[1A\u001b[1M> Filtering background map(s) ...\n",
      "\u001b[1A\u001b[1M> Computing backgound d-map ...\n",
      "\u001b[1A\u001b[1M> Computing backgound-noise d-map ...\n",
      "\u001b[1A    Background: 2052.028   RMS: 70.51974\n",
      "\n",
      "\u001b[1M> Reading SUM_Aligned_20240119_I_Rotated.fits\n",
      "\u001b[1A\u001b[1M> Resampling SUM_Aligned_20240119_I_Rotated.fits ...\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1M> Resampling line:      0 / 1972   \n",
      "\u001b[1A\u001b[1M> Resampling line:    251 / 1972   \n",
      "\u001b[1A\u001b[1M> Resampling line:    502 / 1972   \n",
      "\u001b[1A\u001b[1M> Resampling line:    753 / 1972   \n",
      "\u001b[1A\u001b[1M> Resampling line:   1004 / 1972   \n",
      "\u001b[1A\u001b[1M> Resampling line:   1255 / 1972   \n",
      "\u001b[1A\u001b[1M> Resampling line:   1506 / 1972   \n",
      "\u001b[1A\u001b[1M> Resampling line:   1757 / 1972   \n",
      "\u001b[1A\u001b[1M> Closing files ...\n",
      "\u001b[1A\u001b[1M> \n",
      "\u001b[1A> All done (in 0.3 s)\n"
     ]
    }
   ],
   "source": [
    "# single swarp command:\n",
    "# Determmine image size...\n",
    "ref_image = fits.open(ref_image_name)\n",
    "ref_hdr = ref_image[0].header\n",
    "XSIZE=ref_hdr['NAXIS1']-10# could be wrong order!\n",
    "YSIZE=ref_hdr['NAXIS2']-10\n",
    "print(\"Image sizes:\",XSIZE,YSIZE)\n",
    "ref_image.close()\n",
    "\n",
    "try:\n",
    "    #command = \"swarp %s %s -c %s -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N\" % (sci_image_name, ref_image_name, os.path.join(config_dir, 'config.swarp'))\n",
    "    command = \"swarp %s %s -c %s -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N -IMAGE_SIZE YSIZE,XSIZE\" % (sci_image_name, ref_image_name, os.path.join(config_dir, 'config.swarp'))\n",
    "    #command = \"swarp @%s -c %s -SUBTRACT_BACK N -RESAMPLE Y -RESAMPLE_DIR . -COMBINE N -IMAGE_SIZE 1800,900\" % (swarp_filelist_name, os.path.join(config_dir, 'config.swarp'))\n",
    "    print('Executing command: %s' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SWarp with exit error %s'%err)\n",
    "    \n",
    "sci_image_aligned_name = sci_image_name.replace(\".fits\", \".resamp.fits\").replace('data','processed')\n",
    "ref_image_aligned_name = ref_image_name.replace(\".fits\", \".resamp.fits\").replace('data','processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aed9a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nalign_image_array\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "align_image_array\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67502f19",
   "metadata": {},
   "source": [
    "And AstroImageJ verifies this basically looks right - but notice again the cropping might not make that such sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0699105c",
   "metadata": {},
   "source": [
    "I think for debug, let's try to subtract two images right here. Altohugh note that there is another refinement step later, so even if bad here, maybe don't care?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d093cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUM_Aligned_20240119_I_Rotated.resamp.fits'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_image_aligned_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ceafa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUM_Aligned_20230308_I_Rotated.resamp.fits'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_image_aligned_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc9197e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1970,2385) (1972,2384) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16428/741750281.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Perform the image subtraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# looks like creating a new fits image, so going back to that tutorial....\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimage_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msci_image_aligned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mref_image_aligned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mhdu_image_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrimaryHDU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mhdu_image_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sub_test_0.fits\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1970,2385) (1972,2384) "
     ]
    }
   ],
   "source": [
    "# Test image subtract - SINGLE IMAGE TEST ONLY!\n",
    "ref_image_aligned = fits.open(ref_image_aligned_name)\n",
    "hdr_ref = ref_image_aligned[0].header #save fits header\n",
    "sci_image_aligned = fits.open(sci_image_aligned_name)\n",
    "hdr_sci = sci_image_aligned[0].header #save fits header\n",
    "\n",
    "# Perform the image subtraction\n",
    "# looks like creating a new fits image, so going back to that tutorial....\n",
    "image_sub = sci_image_aligned[0].data - ref_image_aligned[0].data\n",
    "hdu_image_sub = fits.PrimaryHDU(image_sub)\n",
    "hdu_image_sub.writeto(\"sub_test_0.fits\", overwrite = True)\n",
    "\n",
    "# Plot up the result of the image subtraction\n",
    "mean, median, std = sigma_clipped_stats(hdu_image_sub.data)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# Set the scale of the image based on its statistics\n",
    "plt.imshow(hdu_image_sub.data, vmin=median-2*std, vmax=median+2*std, cmap='gray')\n",
    "plt.colorbar(shrink=0.4)\n",
    "plt.title('Test image subtraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2379dd98",
   "metadata": {},
   "source": [
    "Might actually look better than their example, but the fact the apparently rotation might be the actual problem..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b207d2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Background Subtraction\n",
    "- Mask sources in images\n",
    "- Use 3 sigma clipping to filter data and accurately measure the backgorund\n",
    "- Then split image into 300x300 pixel boxes and apply 2x2 median filter\n",
    "\n",
    "That was the original. We are going to (for the first image)\n",
    "\n",
    "1) look at the scalar background\n",
    "2) look at the 2D background with no mask\n",
    "3) look at the 2D background a mask\n",
    "\n",
    "And then assume (3) is best and go ahead with subtracting them all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eventually do this for each image in the array.\n",
    "image = sci_image_aligned # remove for multi image!\n",
    "#image = fits.open(align_image_array[0])\n",
    "hdr = image[0].header #save fits header\n",
    "\n",
    "#estimate scalar background with sourcemask\n",
    "sigma_clip = SigmaClip(sigma=3.0, maxiters=10)\n",
    "threshold = detect_threshold(image[0].data, nsigma=2.0, sigma_clip=sigma_clip)\n",
    "segment_img = detect_sources(image[0].data, threshold, npixels=10)\n",
    "footprint = circular_footprint(radius=10) #watch this footprint value, should be inspected!\n",
    "mask = segment_img.make_source_mask(footprint=footprint)\n",
    "mean, median, std = sigma_clipped_stats(image[0].data, sigma=3.0, mask=mask)\n",
    "print((mean, median, std))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da24c6",
   "metadata": {},
   "source": [
    "Somehow we should evaluate that..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef879c56",
   "metadata": {},
   "source": [
    "ok but I think for real we just SKIP those scalar, and go right for the 2D background estimator (50x50 box, 3x3 median filter). First image first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67804447",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_estimator = MedianBackground()\n",
    "sigma_clip = SigmaClip(sigma=3.0)\n",
    "bkg = Background2D(image[0].data, (50, 50), filter_size=(3, 3),sigma_clip=sigma_clip, bkg_estimator=bkg_estimator)\n",
    "plt.imshow(bkg.background, origin='lower', cmap='Greys_r',interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f946a",
   "metadata": {},
   "source": [
    "I suppose there is some effect of the background stars here - since we are not doing any masking. Let's try the same mask from above, and see if it gets any better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg = Background2D(image[0].data, (50, 50), filter_size=(3, 3),sigma_clip=sigma_clip, bkg_estimator=bkg_estimator,mask=mask)\n",
    "plt.imshow(bkg.background, origin='lower', cmap='Greys_r',interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9344289",
   "metadata": {},
   "source": [
    "yyyeaahh I guess that's better, the background should probably be NOT bumpy at all. So use this and background subtract everything.\n",
    "\n",
    "(Background goes negative here, I had real problems in AIJ with that....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b155fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just do this twice for the single image test!\n",
    "# measure and subtract the background for science image\n",
    "bkg = Background2D(image[0].data, (50, 50), filter_size=(3, 3),sigma_clip=sigma_clip, bkg_estimator=bkg_estimator,mask=mask)\n",
    "sci_bkg_subtract_name=sci_image_aligned_name.replace(\".resamp.fits\", \"_bkgsub.fits\")\n",
    "image[0].data = image[0].data - bkg.background\n",
    "hdu_image_sub = fits.PrimaryHDU(image[0].data,image[0].header) #added headers!\n",
    "hdu_image_sub.writeto(sci_bkg_subtract_name,overwrite=True)\n",
    "# measure and subtract the background for reference image\n",
    "image = ref_image_aligned\n",
    "bkg = Background2D(image[0].data, (50, 50), filter_size=(3, 3),sigma_clip=sigma_clip, bkg_estimator=bkg_estimator,mask=mask)\n",
    "ref_bkg_subtract_name=ref_image_aligned_name.replace(\".resamp.fits\", \"_bkgsub.fits\")\n",
    "image[0].data = image[0].data - bkg.background\n",
    "hdu_image_sub = fits.PrimaryHDU(image[0].data,image[0].header) #added headers!\n",
    "hdu_image_sub.writeto(ref_bkg_subtract_name,overwrite=True)\n",
    "\n",
    "# Check those in AIJ: both seem kinda background-subtracted! (zero or below!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb40c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Do this for each image in the array.\n",
    "bkg_subtract_array=[]\n",
    "for i in range(len(align_image_array)):\n",
    "    image = fits.open(align_image_array[i])\n",
    "    hdr = image[0].header #save fits header\n",
    "    # measure and subtract the background\n",
    "    bkg = Background2D(image[0].data, (50, 50), filter_size=(3, 3),sigma_clip=sigma_clip, bkg_estimator=bkg_estimator,mask=mask)\n",
    "    bkg_subtract_name=align_image_array[i].replace(\".resamp.fits\", \"_bkgsub.fits\")\n",
    "    bkg_subtract_array.append(bkg_subtract_name)\n",
    "    image[0].data = image[0].data - bkg.background\n",
    "    hdu_image_sub = fits.PrimaryHDU(image[0].data,image[0].header) #added headers!\n",
    "    hdu_image_sub.writeto(bkg_subtract_name,overwrite=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a4e78",
   "metadata": {},
   "source": [
    "These images look right, but I did get an error that these images are now double precision, whereas AIJ expects single precision. Fine for now?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "bkg_subtract_array\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd53420",
   "metadata": {},
   "source": [
    "## PSF matching\n",
    "\n",
    "The atmosphere heavily affects the PSF of the images by determining the \"seeing\" conditions. The seeing for ground-based optical telescopes is usually measured as the FWHM of the imaging PSF.  Properties of the atmosphere can change very rapidly, so it is rare that science and reference images are characterized by the same seeing. Therefore their PSFs are usually different, which is a problem for image subtraction. \n",
    "\n",
    "\n",
    "### Generate the kernel for the convolution\n",
    "\n",
    "The PSF of the science and reference images can be matched in several different ways.  Here we start by performing a first source extraction on the reference image (which we assume to be the last in the list).  We can use the catalogs of sources that we obtain for two main purposes: <br />\n",
    "1. Measure the PSF of the science (reference?) frame, using PSFex or photutils\n",
    "2. Obtain instruments magnitudes that will be the basis for the zero-point calibration (see Photometry module).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bkg_subtract_array[len(bkg_subtract_array)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13309d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use REFERENCE image to extract sources.\n",
    "# overwriting the catalog, but I guess that doesn't matter much.\n",
    "\n",
    "ref_image_bkgsub_name = ref_bkg_subtract_name # SWTICH when you go back to multi image!\n",
    "#ref_image_bkgsub_name = os.path.join(proc_dir, bkg_subtract_array[len(bkg_subtract_array)-1])\n",
    "\n",
    "if os.path.exists('prepsfex.cat'): #Remove possible temporary files\n",
    "    os.remove(\"prepsfex.cat\") \n",
    "\n",
    "try:\n",
    "    #command = \"sextractor %s -c %s -CATALOG_NAME %s -MAG_ZEROPOINT 25.0\" % (sci_image_aligned_name, os.path.join(data_dir, 'prepsfex.sex'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "    #command = \"source-extractor %s -c %s -CATALOG_NAME %s -MAG_ZEROPOINT 25.0\" % (sci_image_aligned_name, os.path.join(data_dir, 'prepsfex.sex'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "    command = \"source-extractor %s -c %s -CATALOG_NAME %s -MAG_ZEROPOINT 25.0\" % (ref_image_bkgsub_name, os.path.join(data_dir,'prepsfex.sex'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SExtractor with exit error %s'%err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b47cb8d",
   "metadata": {},
   "source": [
    "Now we use another software part of the AstrOmatic suite, PSFex, to **measure the PSF of the reference image(s)**. PSFex estimates the PSF based on the information present in the catalog generated with SExtractor.  Then, let's plot the PSF model obtained with PSFex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662cc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PSFex to compute PSF, read and display the final model; needs to output to \"out\" dir.\n",
    "if not os.path.isdir('out'): os.mkdir('out')\n",
    "\n",
    "try:\n",
    "    command = \"psfex prepsfex.cat -c psfex_conf.psfex\"\n",
    "    #command = \"psfex %s -c %s\" % (source_extract_cat_name,psfex_config_name)\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run psfex with exit error %s'%err)\n",
    "\n",
    "psf_ref_image_name = os.path.join(out_dir,'proto_prepsfex.fits') # temporary name?\n",
    "print(psf_ref_image_name)\n",
    "psf_ref_image = fits.open(psf_ref_image_name)\n",
    "\n",
    "plt.imshow(psf_ref_image[0].data[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43cad4",
   "metadata": {},
   "source": [
    "mostly round ball...as expected..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a1102",
   "metadata": {},
   "source": [
    "### Convolve the reference image with the PSF of each science image\n",
    "\n",
    "Now that the kernel is generated, let's convolve the reference image with the PSF of each science frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ca63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sci_bkg_subtract = fits.open(bkg_subtract_array[2])\n",
    "sci_bkg_subtract[0].header\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9507eee",
   "metadata": {},
   "source": [
    "header is almost empty - in particular it's missing the WCS! (old comment?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1606f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to be deleted when we move to multi images, but notice the science and ref images might be \n",
    "# switched below, incorrectly!\n",
    "\n",
    "# Convolve the kernel of the reference images with the PSF of the science frame\n",
    "kernel_ref = psf_ref_image[0].data[0] # from the PSF we just did...\n",
    "\n",
    "sci_bkg_subtract = fits.open(sci_bkg_subtract_name) # gross!\n",
    "sci_conv = scipy_convolve(sci_bkg_subtract[0].data, kernel_ref, mode='same', method='fft') # convolve step\n",
    "hdu_sci_conv = fits.PrimaryHDU(sci_conv,sci_bkg_subtract[0].header) \n",
    "sci_conv_name=os.path.join(proc_dir,sci_bkg_subtract_name.replace(\".fits\",\"_conv.fits\"))\n",
    "hdu_sci_conv.writeto(sci_conv_name,overwrite=True)\n",
    "\n",
    "#Plot up the convolved reference image\n",
    "mean, median, std = sigma_clipped_stats(hdu_sci_conv.data)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# set the scale of the image based on its statistics\n",
    "plt.imshow(hdu_sci_conv.data, vmin=median-2*std, vmax=median+2*std)\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Convolved science image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5a279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Convolve the kernel of the reference image with the PSF of the science frame\n",
    "kernel_ref = psf_ref_image[0].data[0]\n",
    "\n",
    "# for plotting\n",
    "#fig, axes = plt.subplots(3, math.ceil(len(bkg_subtract_array)/3.))\n",
    "#plt.figure(figsize=(4,4))\n",
    "\n",
    "sci_conv_array=[]\n",
    "for i in range(len(bkg_subtract_array)-1): # don't need to do the last one, that's reference\n",
    "    sci_bkg_subtract = fits.open(bkg_subtract_array[i])\n",
    "    sci_conv = scipy_convolve(sci_bkg_subtract[0].data, kernel_ref, mode='same', method='fft') # convolve step\n",
    "    hdu_sci_conv = fits.PrimaryHDU(sci_conv,sci_bkg_subtract[0].header) # really should be adding header keys!\n",
    "    sci_conv_array.append(bkg_subtract_array[i].replace(\".fits\",\"_conv.fits\"))\n",
    "    sci_conv_name=os.path.join(proc_dir,sci_conv_array[i])\n",
    "    \n",
    "    # Images not being created!\n",
    "    print(sci_conv_name)\n",
    "    hdu_sci_conv.writeto(sci_conv_name,overwrite=True)\n",
    "\n",
    "    #Plot up the convolved reference image\n",
    "    mean, median, std = sigma_clipped_stats(hdu_sci_conv.data)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    # set the scale of the image based on its statistics\n",
    "    # Name looks totally wrong!\n",
    "    plt.imshow(sci_bkg_subtract[0].data, vmin=median-2*std, vmax=median+2*std)\n",
    "    plt.colorbar(shrink = 0.4)\n",
    "    plt.title('Convolved science image')\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb322e2",
   "metadata": {},
   "source": [
    "Kinda hard to tell they are changing, but I think they are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82c4d7",
   "metadata": {},
   "source": [
    "Next step is actually to create a refernce image for each science image, which is the reference convolved with the science. Then each pair should have the same PSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sci_conv_array\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1511a",
   "metadata": {},
   "source": [
    "### Convolve the science image with the PSF of the reference image\n",
    "\n",
    "\n",
    "Same as above, but this time we generate a kernel with the properties of the **PSF of the science image**.  Then, we convolve the reference image with this kernel.\n",
    "\n",
    "I think what is happening here is the PSF data is stored in prepsfex.cat, as an output catalog from source-extractor, so we need to re-run the source extractor to get the PSF of the image in question.\n",
    "\n",
    "Kernel from *each* science image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this step after the single image test is done!\n",
    "# But check the steps after, since this was cut and pasted!\n",
    "\n",
    "# use SCIENCE image to extract sources.\n",
    "# overwriting the catalog, but I guess that doesn't matter much.\n",
    "\n",
    "sci_image_bkgsub_name = sci_bkg_subtract_name # SWTICH when you go back to multi image!\n",
    "#ref_image_bkgsub_name = os.path.join(proc_dir, bkg_subtract_array[len(bkg_subtract_array)-1])\n",
    "\n",
    "if os.path.exists('prepsfex.cat'): #Remove possible temporary files\n",
    "    os.remove(\"prepsfex.cat\") \n",
    "\n",
    "try:\n",
    "    #command = \"sextractor %s -c %s -CATALOG_NAME %s -MAG_ZEROPOINT 25.0\" % (sci_image_aligned_name, os.path.join(data_dir, 'prepsfex.sex'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "    #command = \"source-extractor %s -c %s -CATALOG_NAME %s -MAG_ZEROPOINT 25.0\" % (sci_image_aligned_name, os.path.join(data_dir, 'prepsfex.sex'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "    command = \"source-extractor %s -c %s -CATALOG_NAME %s -MAG_ZEROPOINT 25.0\" % (sci_image_bkgsub_name, os.path.join(data_dir,'prepsfex.sex'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SExtractor with exit error %s'%err)\n",
    "    \n",
    "    \n",
    "# Run PSFex to compute PSF, read and display the final model; needs to output to \"out\" dir.\n",
    "if not os.path.isdir('out'): os.mkdir('out')\n",
    "\n",
    "try:\n",
    "    command = \"psfex prepsfex.cat -c psfex_conf.psfex\"\n",
    "    #command = \"psfex %s -c %s\" % (source_extract_cat_name,psfex_config_name)\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run psfex with exit error %s'%err)\n",
    "\n",
    "psf_sci_image_name = os.path.join(out_dir,'proto_prepsfex.fits') # temporary name?\n",
    "print(psf_sci_image_name)\n",
    "psf_sci_image = fits.open(psf_sci_image_name)\n",
    "\n",
    "plt.imshow(psf_sci_image[0].data[0], cmap='gray')\n",
    "\n",
    "# this is to be deleted when we move to multi images, but notice the science and ref images might be \n",
    "# switched below, incorrectly!\n",
    "\n",
    "# Convolve the kernel of the SCIENCE images with the PSF of the reference frame\n",
    "kernel_sci = psf_sci_image[0].data[0] # from the PSF we just did...\n",
    "\n",
    "ref_bkg_subtract = fits.open(ref_bkg_subtract_name) # gross!\n",
    "ref_conv = scipy_convolve(ref_bkg_subtract[0].data, kernel_sci, mode='same', method='fft') # convolve step\n",
    "hdu_ref_conv = fits.PrimaryHDU(ref_conv,ref_bkg_subtract[0].header) \n",
    "ref_conv_name=os.path.join(proc_dir,ref_bkg_subtract_name.replace(\".fits\",\"_conv.fits\"))\n",
    "hdu_ref_conv.writeto(ref_conv_name,overwrite=True)\n",
    "\n",
    "#Plot up the convolved reference image\n",
    "mean, median, std = sigma_clipped_stats(hdu_ref_conv.data)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# set the scale of the image based on its statistics\n",
    "plt.imshow(hdu_ref_conv.data, vmin=median-2*std, vmax=median+2*std)\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Convolved reference image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760bd6fc",
   "metadata": {},
   "source": [
    "Checking in AIJ, the resulting images have nearly the same PSF! (checking a few example sources, and they even seem to have the same pixel location values, which is good for us!\n",
    "\n",
    "bright stars do have halos, which might be screwing up the background calculation, or the PSF? If we are eventually going to just subtract a circle, this might not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee97312",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ref_conv_array=[]\n",
    "for i in range(len(bkg_subtract_array)-1): # don't need to do the last one, that's the reference\n",
    "    sci_image_bkgsub_name = os.path.join(proc_dir, bkg_subtract_array[i])\n",
    "\n",
    "    try:\n",
    "        command = \"source-extractor %s -c %s -CATALOG_NAME %s -MAG_ZEROPOINT 25.0\" % (sci_image_bkgsub_name, os.path.join(data_dir,'prepsfex.sex'), os.path.join(proc_dir, 'prepsfex.cat'))\n",
    "        print('Executing command: %s\\n' % command)\n",
    "        rval = subprocess.run(command.split(), check=True)\n",
    "        print('Success!')\n",
    "    except subprocess.CalledProcessError as err:\n",
    "        print('Could not run SExtractor with exit error %s'%err)\n",
    "     \n",
    "    # Run PSFex to compute PSF, read and display the final model; needs to output to \"out\" dir.\n",
    "    if not os.path.isdir('out'): os.mkdir('out') # should be made already\n",
    "\n",
    "    try:\n",
    "        command = \"psfex prepsfex.cat -c psfex_conf.psfex\"\n",
    "        print('Executing command: %s\\n' % command)\n",
    "        rval = subprocess.run(command.split(), check=True)\n",
    "        print('Success!')\n",
    "    except subprocess.CalledProcessError as err:\n",
    "        print('Could not run psfex with exit error %s'%err)\n",
    "\n",
    "    psf_sci_image_name = os.path.join(out_dir,'proto_prepsfex.fits') # DEFAULT name\n",
    "    #psf_sci_image_name = os.path.join(out_dir,bkg_subtract_array[i].replace('.fits','_protoPSF.fits')) # rewriting each time!\n",
    "    print(psf_sci_image_name)\n",
    "    psf_sci_image = fits.open(psf_sci_image_name)\n",
    "    # only the last image shows...\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(psf_sci_image[0].data[0], cmap='gray')       \n",
    "    plt.title('Science Image PSF')\n",
    "    plt.show()   \n",
    "        \n",
    "    # Convolve the reference image with the PSF of each science frame\n",
    "    # Grab the kernel!\n",
    "    kernel_sci = psf_sci_image[0].data[0]\n",
    "    \n",
    "    # careful naming scheme needed!\n",
    "    ref_bkg_subtract = fits.open(bkg_subtract_array[len(bkg_subtract_array)-1]) # REFERENCE IS LAST IMAGE!\n",
    "    ref_conv = scipy_convolve(ref_bkg_subtract[0].data, kernel_sci, mode='same', method='fft') # convolve step\n",
    "    hdu_ref_conv = fits.PrimaryHDU(ref_conv,ref_bkg_subtract[0].header) # really should be adding header keys!\n",
    "    \n",
    "    ref_conv_array.append(bkg_subtract_array[i].replace(\".fits\",\"_refconv.fits\"))\n",
    "    ref_conv_name=os.path.join(proc_dir,ref_conv_array[i])\n",
    "    \n",
    "    #ref_conv_name=os.path.join(proc_dir,bkg_subtract_array[i].replace(\".fits\",\"_refconv.fits\"))\n",
    "    \n",
    "    \n",
    "    # Images not being created!\n",
    "    print(ref_conv_name)\n",
    "    hdu_ref_conv.writeto(ref_conv_name,overwrite=True)\n",
    "\n",
    "    #Plot up the convolved reference image\n",
    "    mean, median, std = sigma_clipped_stats(hdu_ref_conv.data)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    # set the scale of the image based on its statistics\n",
    "    plt.imshow(ref_bkg_subtract[0].data, vmin=median-2*std, vmax=median+2*std)\n",
    "    plt.colorbar(shrink = 0.4)\n",
    "    plt.title('Convolved science image')\n",
    "    plt.show()\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ref_conv_array\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb25ab2",
   "metadata": {},
   "source": [
    "These guys now DO have WCS headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a4bcd7",
   "metadata": {},
   "source": [
    "(I think this step should go inside the normalization loop somewhere, so skipping to that...)\n",
    "\n",
    "### Improving the alignment\n",
    "Now that the science image is convolved with (an approximation of) the PSF of the reference image, \n",
    "and the reference image is convolved with the PSF of the science image, we can perform the image subtraction.\n",
    "\n",
    "- Before the subtraction we use an fft method (chi_2_shift) to fine-tune the image alignment of the reference and science image. We'll do this in pairs, reference aligning with science. When we go do photometry with AIJ, this fine tuning doesn't matter so much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f904a",
   "metadata": {},
   "source": [
    "## Normalization of the images\n",
    "\n",
    "The science and reference images are usually obtained with different exposure times.  In addition, the reference image can be the stack of several images to increase the depth.  Finally, different CCDs of the same camera (or even different regions of the same CCD when multiple amplifiers are present) may have slightly different gain. <br >\n",
    "\n",
    "The background subtraction should have removed the non-linear offsets between science and reference images.  We can therefore normalize the two images by computing the ratio of bright star fluxes in the two images. Once again, we use SExtractor to extract the flux and other quantities.\n",
    "\n",
    "We should be able to do this pairwise as well, as the offsets between different science images should be taken care of with our differential photometry. So we'll maybe normalize the reference(s) to the science?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f467206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove this block once the single-image test is done!\n",
    "\n",
    "# Run SExtractor on the science image\n",
    "print(sci_conv_name)\n",
    "print(ref_conv_name)\n",
    "    \n",
    "sextractor_command = \"source-extractor %s -c prepsfex.sex -CATALOG_NAME sci_match.cat -MAG_ZEROPOINT 25.0 -CATALOG_TYPE=ASCII_HEAD\" % (sci_conv_name)\n",
    "\n",
    "try:\n",
    "    command = sextractor_command\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SExtractor with exit error %s'%err)\n",
    "\n",
    "cat_sci = ascii.read('sci_match.cat') # dummy, should be able to rewrite constantly\n",
    "    \n",
    "# Run SExtractor on the reference image\n",
    "sextractor_command = \"source-extractor %s -c prepsfex.sex -CATALOG_NAME ref_match.cat -MAG_ZEROPOINT 25.0 -CATALOG_TYPE=ASCII_HEAD\" % (ref_conv_name)\n",
    "\n",
    "try:\n",
    "    command = sextractor_command\n",
    "    print('Executing command: %s\\n' % command)\n",
    "    rval = subprocess.run(command.split(), check=True)\n",
    "    print('Success!')\n",
    "except subprocess.CalledProcessError as err:\n",
    "    print('Could not run SExtractor with exit error %s'%err)\n",
    "\n",
    "# Read in the SExtractor output catalog\n",
    "cat_ref = ascii.read('ref_match.cat')\n",
    "    \n",
    "# Match the catalog of sources of the reference and science images.  \n",
    "# Calculate the ratio between the flux of source in the science image over the flux of sources \n",
    "# in the reference image.\n",
    "    \n",
    "c_sci = SkyCoord(ra=cat_sci['X_WORLD'], dec=cat_sci['Y_WORLD'])\n",
    "c_ref = SkyCoord(ra=cat_ref['X_WORLD'], dec=cat_ref['Y_WORLD'])\n",
    "\n",
    "idx, d2d, d3d = c_sci.match_to_catalog_3d(c_ref)\n",
    "\n",
    "# Initialize a list for the indexes and one for the flux ratios\n",
    "# for each (sci, ref) pair, don't need to save all this?\n",
    "index_arr = []\n",
    "ratio_arr = []\n",
    "\n",
    "# Sure don't need to be printing all this stuff! Is there a final normalization i can use for checking?\n",
    "for j, i2, d in zip(idx, np.arange(len(d2d)),d2d):\n",
    "    #print(i,d)\n",
    "    #index_arr.append(i)\n",
    "    #print(\"Image coordinates\")\n",
    "    #print(cat_ref['X_IMAGE'][i],cat_ref['Y_IMAGE'][i],'  ', cat_sci['X_IMAGE'][i2],cat_sci['Y_IMAGE'][i2])\n",
    "    #print('Fluxes and flux ratio')\n",
    "    #print(cat_ref['FLUX_AUTO'][i], cat_sci['FLUX_AUTO'][i2], cat_sci['FLUX_AUTO'][i2] / cat_ref['FLUX_AUTO'][i])\n",
    "    ratio_arr.append(cat_sci['FLUX_AUTO'][i2] / cat_ref['FLUX_AUTO'][j]) # Ratio of SCI/REF!\n",
    "    \n",
    "scale = np.median(ratio_arr)\n",
    "print(\"The scaling factor is\", scale)\n",
    "    \n",
    "# fine tune the alignment here - at least without this, the alginment is terrible!\n",
    "# this line might need to include rotation...\n",
    "sci_image = fits.open(sci_conv_name)\n",
    "ref_image = fits.open(ref_conv_name)\n",
    "## Check the images...set the scale of the image based on its statistics\n",
    "mean, median, std = sigma_clipped_stats(sci_image[0].data)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(sci_image[0].data, vmin=median-2*std, vmax=median+2*std)\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Convolved sicence image')\n",
    "plt.show()\n",
    "mean, median, std = sigma_clipped_stats(ref_image[0].data)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(ref_image[0].data, vmin=median-2*std, vmax=median+2*std)\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('Convolved reference image')\n",
    "plt.show()\n",
    "# They look right!\n",
    "\n",
    "xoff, yoff, exoff, eyoff = chi2_shift(ref_image[0].data, sci_image[0].data, 10, return_error=True, upsample_factor='auto')\n",
    "print(\"Alignment offsets:\",xoff,yoff)\n",
    "sci_image_shift = scipy.ndimage.shift(sci_image[0].data, [-yoff, -xoff], order=3, mode='reflect', cval=0.0, prefilter=True)\n",
    "    \n",
    "# Rescale the reference image to the science and perform the image subtraction.\n",
    "image_sub = sci_image_shift-ref_image[0].data*scale\n",
    "hdu_image_sub = fits.PrimaryHDU(image_sub) # needs a header!\n",
    "#sub_array.append(sci_conv_name.replace(\".fits\",\"_diff.fits\")) # move to the out directory\n",
    "hdu_image_sub.writeto(sci_conv_name.replace(\".fits\",\"_diff.fits\"),overwrite=True)\n",
    "\n",
    "## Check the images...set the scale of the image based on its statistics\n",
    "mean, median, std = sigma_clipped_stats(image_sub)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(image_sub, vmin=median-2*std, vmax=median+2*std)\n",
    "plt.colorbar(shrink = 0.4)\n",
    "plt.title('difference image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357dd3b3",
   "metadata": {},
   "source": [
    "No - but notice how the errors are different on different sides of the image? It's a rotation problem, probably from the very beginning! Even using two science images, the shift is bad. Doesn't look as bad as with the reference, but still pretty bad. Is the rotation script bad? Worked on the rotation a bit - maybe you just can't subtract images this big, you'll always have strange shifting?\n",
    "\n",
    "Thinking a little more carefully - the WCS doesn't guarantee that the subtraction is done at the coordinate level, right? It tell you how to convert to (RA,Dec) as you move around the image, but if the image has distortions at the pixel level, the subtraction is *never* going to look that great.\n",
    "\n",
    "Solution: Reduce the size of the subtractioned section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sub_array=[]\n",
    "for i in range(len(bkg_subtract_array)-1): # don't need to do the last one, that's the reference\n",
    "    \n",
    "    # Run SExtractor on the science image\n",
    "    sextractor_command = \"source-extractor %s -c prepsfex.sex -CATALOG_NAME sci_match.cat -MAG_ZEROPOINT 25.0 -CATALOG_TYPE=ASCII_HEAD\" % (sci_conv_array[i])\n",
    "\n",
    "    try:\n",
    "        command = sextractor_command\n",
    "        print('Executing command: %s\\n' % command)\n",
    "        rval = subprocess.run(command.split(), check=True)\n",
    "        print('Success!')\n",
    "    except subprocess.CalledProcessError as err:\n",
    "        print('Could not run SExtractor with exit error %s'%err)\n",
    "\n",
    "    cat_sci = ascii.read('sci_match.cat') # dummy, should be able to rewrite constantly\n",
    "    \n",
    "    # Run SExtractor on the reference image\n",
    "    sextractor_command = \"source-extractor %s -c prepsfex.sex -CATALOG_NAME ref_match.cat -MAG_ZEROPOINT 25.0 -CATALOG_TYPE=ASCII_HEAD\" % (ref_conv_array[i])\n",
    "\n",
    "    try:\n",
    "        command = sextractor_command\n",
    "        print('Executing command: %s\\n' % command)\n",
    "        rval = subprocess.run(command.split(), check=True)\n",
    "        print('Success!')\n",
    "    except subprocess.CalledProcessError as err:\n",
    "        print('Could not run SExtractor with exit error %s'%err)\n",
    "\n",
    "    # Read in the SExtractor output catalog\n",
    "    cat_ref = ascii.read('ref_match.cat')\n",
    "    \n",
    "    # Match the catalog of sources of the reference and science images.  \n",
    "    # Calculate the ratio between the flux of source in the science image over the flux of sources \n",
    "    # in the reference image.\n",
    "    \n",
    "    # Getting lattitude angles of like 800 degrees, so something is wrong with the WCS.\n",
    "    # Confirmed, these images do not have WCS! which ones still do....\n",
    "    # bgsub do not...\n",
    "    # Rotated do not! That's gotta be it...\n",
    "    \n",
    "    \n",
    "    c_sci = SkyCoord(ra=cat_sci['X_WORLD'], dec=cat_sci['Y_WORLD'])\n",
    "    c_ref = SkyCoord(ra=cat_ref['X_WORLD'], dec=cat_ref['Y_WORLD'])\n",
    "\n",
    "    idx, d2d, d3d = c_sci.match_to_catalog_3d(c_ref)\n",
    "\n",
    "    # Initialize a list for the indexes and one for the flux ratios\n",
    "    # for each (sci, ref) pair, don't need to save all this?\n",
    "    index_arr = []\n",
    "    ratio_arr = []\n",
    "\n",
    "    # Sure don't need to be printing all this stuff! Is there a final normalization i can use for checking?\n",
    "    for j, i2, d in zip(idx, np.arange(len(d2d)),d2d):\n",
    "        #print(i,d)\n",
    "        #index_arr.append(i)\n",
    "        #print(\"Image coordinates\")\n",
    "        #print(cat_ref['X_IMAGE'][i],cat_ref['Y_IMAGE'][i],'  ', cat_sci['X_IMAGE'][i2],cat_sci['Y_IMAGE'][i2])\n",
    "        #print('Fluxes and flux ratio')\n",
    "        #print(cat_ref['FLUX_AUTO'][i], cat_sci['FLUX_AUTO'][i2], cat_sci['FLUX_AUTO'][i2] / cat_ref['FLUX_AUTO'][i])\n",
    "        ratio_arr.append(cat_sci['FLUX_AUTO'][i2] / cat_ref['FLUX_AUTO'][j]) # Ratio of SCI/REF!\n",
    "    \n",
    "    scale = np.median(ratio_arr)\n",
    "    print(\"The scaling factor is\", scale)\n",
    "    \n",
    "    # fine tune the alignment here - at least without this, the alginment is terrible!\n",
    "    sci_image = fits.open(sci_conv_array[i])\n",
    "    ref_image = fits.open(ref_conv_array[i])\n",
    "    xoff, yoff, exoff, eyoff = chi2_shift(sci_image[0].data, ref_image[0].data, 10, return_error=True, upsample_factor='auto')\n",
    "    print(\"Alignment offsets:\",xoff,yoff)\n",
    "    ref_image_shift = scipy.ndimage.shift(ref_image[0].data, [-yoff, -xoff], order=3, mode='reflect', cval=0.0, prefilter=True)\n",
    "    \n",
    "    # Rescale the reference image to the science and perform the image subtraction.\n",
    "    image_sub = sci_image[0].data-ref_image_shift*scale\n",
    "    hdu_image_sub = fits.PrimaryHDU(image_sub) # needs a header!\n",
    "    sub_array.append(sci_conv_array[i].replace(\".fits\",\"_diff.fits\")) # move to the out directory\n",
    "    hdu_image_sub.writeto(\"out/\"+sub_array[i],overwrite=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb567b",
   "metadata": {},
   "source": [
    "they do not look great, let's plot to evaluate more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(bkg_subtract_array)-1, 2,figsize=(50,50))\n",
    "for i in range(len(bkg_subtract_array)-1):\n",
    "    sci_image = fits.open(sci_conv_array[i])\n",
    "    sub_image = fits.open(sub_array[i])\n",
    "    \n",
    "    mean, median, std = sigma_clipped_stats(sub_image[0].data)\n",
    "    axs[i,0].imshow(sub_image[0].data[600:1200,600:1200], vmin=median-2*std, vmax=median+2*std, cmap='gray')\n",
    "        \n",
    "    mean, median, std = sigma_clipped_stats(sci_image[0].data)\n",
    "    axs[i,1].imshow(sci_image[0].data[600:1200,600:1200], vmin=median-2*std, vmax=median+2*std, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48144a1",
   "metadata": {},
   "source": [
    " Well the galaxy seems to have disappeared, but the PSF matching certainly does not look great. \n",
    " \n",
    " \"Not algined\" is my diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43f2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
